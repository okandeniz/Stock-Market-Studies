{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c3d8e2-dd99-484f-86e4-31b0af2bfdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b36d37-d86d-444e-aa10-135aef2bc8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kodlar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADEL.IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADGYO.IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGHOL.IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGROT.IS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHGAZ.IS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Kodlar\n",
       "0   ADEL.IS\n",
       "1  ADGYO.IS\n",
       "2  AGHOL.IS\n",
       "3  AGROT.IS\n",
       "4  AHGAZ.IS"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"Bist100_duznelenmis.xlsx\",header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2ca3bc-97df-4d02-bb53-55007a81ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = data[\"Kodlar\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a9e046-f597-4e47-ac78-565bf72db21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [\"NetIncomeFromContinuingOperations\",\n",
    "         \"TotalAssets\",\n",
    "         \"OperatingCashFlow\",\n",
    "         \"LongTermDebtAndCapitalLeaseObligation\",\n",
    "         \"TotalNonCurrentLiabilitiesNetMinorityInterest\",\n",
    "         \"CurrentAssets\",\n",
    "         \"CurrentLiabilities\",\n",
    "         \"StockholdersEquity\",\n",
    "         \"TotalRevenue\",\n",
    "         \"GrossProfit\"] # change as required\n",
    "\n",
    "indx = [\"NetIncome\",\"TotAssets\",\"CashFlowOps\",\"LTDebt\",\"TotLTLiab\",\n",
    "        \"CurrAssets\",\"CurrLiab\",\"CommStock\",\"TotRevenue\",\"GrossProfit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90991b2-d506-4957-b372-41a7cb4098bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data extracted for  ADEL.IS\n",
      "data extracted for  ADGYO.IS\n",
      "data extracted for  AGHOL.IS\n",
      "data extracted for  AGROT.IS\n",
      "data extracted for  AHGAZ.IS\n",
      "data extracted for  AKCNS.IS\n",
      "data extracted for  AKFGY.IS\n",
      "data extracted for  AKFIS.IS\n",
      "data extracted for  AKFYE.IS\n",
      "data extracted for  AKSGY.IS\n",
      "data extracted for  AKSA.IS\n",
      "data extracted for  AKSEN.IS\n",
      "data extracted for  ALGYO.IS\n",
      "data extracted for  ALARK.IS\n",
      "data extracted for  ALFAS.IS\n",
      "data extracted for  ALTNY.IS\n",
      "data extracted for  AEFES.IS\n",
      "data extracted for  ARCLK.IS\n",
      "data extracted for  ARDYZ.IS\n",
      "data extracted for  ARMGD.IS\n",
      "data extracted for  ASGYO.IS\n",
      "data extracted for  ASELS.IS\n",
      "data extracted for  ASTOR.IS\n",
      "data extracted for  ATAKP.IS\n",
      "data extracted for  ATATP.IS\n",
      "data extracted for  AVPGY.IS\n",
      "data extracted for  AYDEM.IS\n",
      "data extracted for  AYGAZ.IS\n",
      "data extracted for  AZTEK.IS\n",
      "BASGZ.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  BTCIM.IS\n",
      "data extracted for  BSOKE.IS\n",
      "data extracted for  BERA.IS\n",
      "data extracted for  BJKAS.IS\n",
      "data extracted for  BIENY.IS\n",
      "data extracted for  BIMAS.IS\n",
      "data extracted for  BINBN.IS\n",
      "data extracted for  BIOEN.IS\n",
      "data extracted for  BOBET.IS\n",
      "data extracted for  BORSK.IS\n",
      "data extracted for  BORLS.IS\n",
      "data extracted for  BRSAN.IS\n",
      "data extracted for  BRYAT.IS\n",
      "data extracted for  BFREN.IS\n",
      "data extracted for  BRISA.IS\n",
      "data extracted for  BUCIM.IS\n",
      "data extracted for  CEMZY.IS\n",
      "data extracted for  CCOLA.IS\n",
      "data extracted for  CVKMD.IS\n",
      "CWENE.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  CANTE.IS\n",
      "data extracted for  CATES.IS\n",
      "data extracted for  CLEBI.IS\n",
      "data extracted for  CIMSA.IS\n",
      "data extracted for  DAPGM.IS\n",
      "data extracted for  DSTKF.IS\n",
      "data extracted for  DEVA.IS\n",
      "data extracted for  DOHOL.IS\n",
      "ARASE.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  DOAS.IS\n",
      "data extracted for  EBEBK.IS\n",
      "data extracted for  ECZYT.IS\n",
      "data extracted for  EFORC.IS\n",
      "data extracted for  EGEEN.IS\n",
      "data extracted for  ECILC.IS\n",
      "data extracted for  EKGYO.IS\n",
      "data extracted for  ENJSA.IS\n",
      "ENERY.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  ENKAI.IS\n",
      "data extracted for  EREGL.IS\n",
      "data extracted for  ESCAR.IS\n",
      "data extracted for  TEZOL.IS\n",
      "data extracted for  EUREN.IS\n",
      "data extracted for  EUPWR.IS\n",
      "data extracted for  FENER.IS\n",
      "data extracted for  FROTO.IS\n",
      "data extracted for  GWIND.IS\n",
      "data extracted for  GSRAY.IS\n",
      "data extracted for  GENIL.IS\n",
      "data extracted for  GESAN.IS\n",
      "data extracted for  GLYHO.IS\n",
      "data extracted for  GOKNR.IS\n",
      "data extracted for  GOLTS.IS\n",
      "data extracted for  GOZDE.IS\n",
      "data extracted for  GRTHO.IS\n",
      "data extracted for  GUBRF.IS\n",
      "data extracted for  GLRMK.IS\n",
      "data extracted for  GRSEL.IS\n",
      "data extracted for  SAHOL.IS\n",
      "data extracted for  HLGYO.IS\n",
      "data extracted for  HRKET.IS\n",
      "data extracted for  HEKTS.IS\n",
      "data extracted for  HTTBT.IS\n",
      "data extracted for  ENTRA.IS\n",
      "data extracted for  INVEO.IS\n",
      "data extracted for  INVES.IS\n",
      "data extracted for  IEYHO.IS\n",
      "data extracted for  INDES.IS\n",
      "data extracted for  IPEKE.IS\n",
      "data extracted for  ISDMR.IS\n",
      "data extracted for  ISFIN.IS\n",
      "data extracted for  ISGYO.IS\n",
      "data extracted for  ISMEN.IS\n",
      "data extracted for  IZENR.IS\n",
      "data extracted for  JANTS.IS\n",
      "data extracted for  KLKIM.IS\n",
      "data extracted for  KLSER.IS\n",
      "data extracted for  KRDMA.IS\n",
      "data extracted for  KRDMD.IS\n",
      "data extracted for  KAREL.IS\n",
      "data extracted for  KARSN.IS\n",
      "data extracted for  KTLEV.IS\n",
      "data extracted for  KAYSE.IS\n",
      "KERVT.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  KLGYO.IS\n",
      "data extracted for  KLRHO.IS\n",
      "data extracted for  KMPUR.IS\n",
      "data extracted for  KCAER.IS\n",
      "data extracted for  KCHOL.IS\n",
      "data extracted for  KONTR.IS\n",
      "data extracted for  KONYA.IS\n",
      "data extracted for  KORDS.IS\n",
      "data extracted for  KOTON.IS\n",
      "data extracted for  KOZAL.IS\n",
      "data extracted for  KOZAA.IS\n",
      "data extracted for  KOPOL.IS\n",
      "data extracted for  KUYAS.IS\n",
      "data extracted for  LIDER.IS\n",
      "data extracted for  LILAK.IS\n",
      "data extracted for  LMKDC.IS\n",
      "data extracted for  LINK.IS\n",
      "data extracted for  LOGO.IS\n",
      "data extracted for  LYDHO.IS\n",
      "data extracted for  MAGEN.IS\n",
      "data extracted for  MAVI.IS\n",
      "data extracted for  MIATK.IS\n",
      "data extracted for  MGROS.IS\n",
      "data extracted for  MPARK.IS\n",
      "data extracted for  MOGAN.IS\n",
      "data extracted for  MOPAS.IS\n",
      "data extracted for  NATEN.IS\n",
      "data extracted for  NTHOL.IS\n",
      "data extracted for  NUHCM.IS\n",
      "data extracted for  OBAMS.IS\n",
      "data extracted for  ODAS.IS\n",
      "data extracted for  ODINE.IS\n",
      "data extracted for  OTKAR.IS\n",
      "data extracted for  OYAKC.IS\n",
      "data extracted for  OZKGY.IS\n",
      "data extracted for  OZATD.IS\n",
      "data extracted for  PAPIL.IS\n",
      "data extracted for  PARSN.IS\n",
      "data extracted for  PASEU.IS\n",
      "data extracted for  PSGYO.IS\n",
      "data extracted for  PATEK.IS\n",
      "data extracted for  PGSUS.IS\n",
      "data extracted for  PEKGY.IS\n",
      "data extracted for  PENTA.IS\n",
      "data extracted for  PEHOL.IS\n",
      "data extracted for  PETKM.IS\n",
      "data extracted for  POLHO.IS\n",
      "POLTK.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  QUAGR.IS\n",
      "data extracted for  RALYH.IS\n",
      "data extracted for  REEDR.IS\n",
      "data extracted for  RYGYO.IS\n",
      "data extracted for  RYSAS.IS\n",
      "data extracted for  RGYAS.IS\n",
      "data extracted for  SARKY.IS\n",
      "data extracted for  SASA.IS\n",
      "data extracted for  SAYAS.IS\n",
      "data extracted for  SDTTR.IS\n",
      "data extracted for  SELEC.IS\n",
      "data extracted for  SRVGY.IS\n",
      "data extracted for  SNGYO.IS\n",
      "data extracted for  SMRTG.IS\n",
      "data extracted for  SUNTK.IS\n",
      "SURGY.IS: Finansal veri çekilemedi, atlanıyor.\n",
      "data extracted for  SUWEN.IS\n",
      "data extracted for  SOKM.IS\n",
      "data extracted for  TABGD.IS\n",
      "data extracted for  TNZTP.IS\n",
      "data extracted for  TATEN.IS\n",
      "data extracted for  TAVHL.IS\n",
      "data extracted for  TKFEN.IS\n",
      "data extracted for  TKNSA.IS\n",
      "data extracted for  TOASO.IS\n",
      "data extracted for  TRGYO.IS\n",
      "data extracted for  TSPOR.IS\n",
      "data extracted for  TUKAS.IS\n",
      "data extracted for  TRCAS.IS\n",
      "data extracted for  TUREX.IS\n",
      "data extracted for  TCELL.IS\n",
      "data extracted for  TMSN.IS\n",
      "data extracted for  TUPRS.IS\n",
      "data extracted for  THYAO.IS\n",
      "data extracted for  TTKOM.IS\n",
      "data extracted for  TTRAK.IS\n",
      "data extracted for  SISE.IS\n",
      "data extracted for  ULKER.IS\n",
      "data extracted for  VAKFN.IS\n",
      "data extracted for  VAKKO.IS\n",
      "data extracted for  VERUS.IS\n",
      "data extracted for  VESBE.IS\n",
      "data extracted for  VESTL.IS\n",
      "data extracted for  YYLGD.IS\n",
      "data extracted for  YEOTK.IS\n",
      "data extracted for  YIGIT.IS\n",
      "data extracted for  ZRGYO.IS\n",
      "data extracted for  ZOREN.IS\n",
      "BINHO.IS: Finansal veri çekilemedi, atlanıyor.\n"
     ]
    }
   ],
   "source": [
    "financial_dir={}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        df1 = yf.Ticker(ticker).get_income_stmt()\n",
    "        df2 = yf.Ticker(ticker).get_balance_sheet()\n",
    "        df3 = yf.Ticker(ticker).get_cashflow()\n",
    "        \n",
    "        if df1.empty or df2.empty or df3.empty or len(df1.columns)<3:\n",
    "            print(f\"{ticker}: Finansal veri çekilemedi, atlanıyor.\")\n",
    "            continue\n",
    "        df1 = df1.iloc[:,:3]\n",
    "        df2 = df2.iloc[:,:3]\n",
    "        df3 = df3.iloc[:,:3]\n",
    "        df = pd.concat([df1,df2,df3])\n",
    "        financial_dir[ticker] = df\n",
    "        print(\"data extracted for \",ticker)\n",
    "        financial_dir[ticker] = df\n",
    "    except Exception as e:\n",
    "        print(ticker,\":\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "963dca62-55c0-4a83-b25a-b2d2f0ef681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_dir[\"TUREX.IS\"].loc[stats,:].isna().sum().sum()>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c880b09a-bae5-4617-8478-9ac19a2cfbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_filter(df, stats, indx, lookback):\n",
    "    \"\"\"Function to filter relevant financial information.\"\"\"\n",
    "    missing_stats = [stat for stat in stats if stat not in df.index]\n",
    "    \n",
    "    if missing_stats:\n",
    "        print(f\"Skipping due to missing stats: {missing_stats}\")\n",
    "        return pd.DataFrame()  # Boş bir DataFrame döndür\n",
    "\n",
    "    existing_stats = [stat for stat in stats if stat in df.index]\n",
    "    df_new = df.loc[existing_stats, df.columns[:lookback]]\n",
    "    df_new.rename(dict(zip(existing_stats, indx[:len(existing_stats)])), inplace=True)\n",
    "    df_new.loc[\"OtherLTDebt\", :] = df_new.loc[\"TotLTLiab\", :] - df_new.loc[\"LTDebt\", :]\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d45601-5adb-4625-94be-bddaf299211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping due to missing stats: ['LongTermDebtAndCapitalLeaseObligation']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['LongTermDebtAndCapitalLeaseObligation', 'GrossProfit']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations', 'LongTermDebtAndCapitalLeaseObligation']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['TotalNonCurrentLiabilitiesNetMinorityInterest', 'CurrentAssets', 'CurrentLiabilities', 'GrossProfit']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations', 'TotalNonCurrentLiabilitiesNetMinorityInterest', 'CurrentAssets', 'CurrentLiabilities', 'GrossProfit']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations', 'TotalNonCurrentLiabilitiesNetMinorityInterest', 'CurrentAssets', 'CurrentLiabilities', 'GrossProfit']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['LongTermDebtAndCapitalLeaseObligation']\n",
      "Skipping due to missing stats: ['LongTermDebtAndCapitalLeaseObligation']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n",
      "Skipping due to missing stats: ['NetIncomeFromContinuingOperations']\n"
     ]
    }
   ],
   "source": [
    "#applying filtering to the finacials\n",
    "transformed_df = {}\n",
    "for ticker in financial_dir:\n",
    "    df_filtered = info_filter(financial_dir[ticker], stats, indx, 3)\n",
    "    if df_filtered.isna().sum().sum()>0:\n",
    "        continue\n",
    "    elif not df_filtered.empty:  # Eğer DataFrame boş değilse ekle\n",
    "        transformed_df[ticker] = df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "321a5a5a-2c0a-4d84-b9ee-9d7da4fb34ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(numerator, denominator, default_value=0):\n",
    "    \"\"\" Bölme işlemi sırasında sıfıra bölünmeyi önlemek için güvenli bölme fonksiyonu. \"\"\"\n",
    "    return numerator / denominator if denominator != 0 else default_value\n",
    "\n",
    "def piotroski_f(df_dict):\n",
    "    \"\"\"Function to calculate F-score of each stock and output information as dataframe.\"\"\"\n",
    "    f_score = {}\n",
    "    for ticker, df in df_dict.items():\n",
    "        if df.empty:  # Eğer DataFrame boşsa atla\n",
    "            print(f\"Skipping {ticker} due to empty dataframe\")\n",
    "            continue\n",
    "        \n",
    "        columns = df.columns\n",
    "        \n",
    "        # Finansal verilerin eksik olup olmadığını kontrol et\n",
    "        try:\n",
    "            tot_assets_0 = df.loc[\"TotAssets\", columns[0]]\n",
    "            tot_assets_1 = df.loc[\"TotAssets\", columns[1]]\n",
    "            tot_assets_2 = df.loc[\"TotAssets\", columns[2]]\n",
    "            \n",
    "            avg_assets_0_1 = safe_divide((tot_assets_0 + tot_assets_1), 2)\n",
    "            avg_assets_1_2 = safe_divide((tot_assets_1 + tot_assets_2), 2)\n",
    "            \n",
    "            roa_0 = safe_divide(df.loc[\"NetIncome\", columns[0]], avg_assets_0_1)\n",
    "            roa_1 = safe_divide(df.loc[\"NetIncome\", columns[1]], avg_assets_1_2)\n",
    "            \n",
    "            ROA_FS = int(roa_0 > 0)\n",
    "            CFO_FS = int(df.loc[\"CashFlowOps\", columns[0]] > 0)\n",
    "            ROA_D_FS = int(roa_0 > roa_1)\n",
    "            CFO_ROA_FS = int(safe_divide(df.loc[\"CashFlowOps\", columns[0]], tot_assets_0) > roa_0)\n",
    "            \n",
    "            LTD_0 = df.loc[\"LTDebt\", columns[0]] + df.loc[\"OtherLTDebt\", columns[0]]\n",
    "            LTD_1 = df.loc[\"LTDebt\", columns[1]] + df.loc[\"OtherLTDebt\", columns[1]]\n",
    "            LTD_FS = int(LTD_0 < LTD_1)\n",
    "            \n",
    "            CR_0 = safe_divide(df.loc[\"CurrAssets\", columns[0]], df.loc[\"CurrLiab\", columns[0]])\n",
    "            CR_1 = safe_divide(df.loc[\"CurrAssets\", columns[1]], df.loc[\"CurrLiab\", columns[1]])\n",
    "            CR_FS = int(CR_0 > CR_1)\n",
    "            \n",
    "            DILUTION_FS = int(df.loc[\"CommStock\", columns[0]] <= df.loc[\"CommStock\", columns[1]])\n",
    "            \n",
    "            GM_0 = safe_divide(df.loc[\"GrossProfit\", columns[0]], df.loc[\"TotRevenue\", columns[0]])\n",
    "            GM_1 = safe_divide(df.loc[\"GrossProfit\", columns[1]], df.loc[\"TotRevenue\", columns[1]])\n",
    "            GM_FS = int(GM_0 > GM_1)\n",
    "            \n",
    "            ATO_0 = safe_divide(df.loc[\"TotRevenue\", columns[0]], avg_assets_0_1)\n",
    "            ATO_1 = safe_divide(df.loc[\"TotRevenue\", columns[1]], avg_assets_1_2)\n",
    "            ATO_FS = int(ATO_0 > ATO_1)\n",
    "            \n",
    "            f_score[ticker] = [ROA_FS, CFO_FS, ROA_D_FS, CFO_ROA_FS, LTD_FS, CR_FS, DILUTION_FS, GM_FS, ATO_FS]\n",
    "        \n",
    "        except KeyError as e:\n",
    "            print(f\"{ticker}: Eksik veri nedeniyle atlanıyor: {e}\")\n",
    "            continue  # Eğer eksik veri varsa hisseyi atla\n",
    "        \n",
    "    f_score_df = pd.DataFrame(f_score, index=[\"PosROA\", \"PosCFO\", \"ROAChange\", \"Accruals\", \"Leverage\", \"Liquidity\", \"Dilution\", \"GM\", \"ATO\"])\n",
    "    return f_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00c0b090-4cdc-4783-9283-b607c1a15ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kod</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOGO.IS</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSRAY.IS</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KARSN.IS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARKY.IS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ECILC.IS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BFREN.IS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TKFEN.IS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADEL.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GUBRF.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DOAS.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CCOLA.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENKAI.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEZOL.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OZKGY.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TCELL.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ATATP.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NUHCM.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ASELS.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AEFES.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AGHOL.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KUYAS.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ISDMR.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MAVI.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CLEBI.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GRSEL.IS</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GLYHO.IS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PENTA.IS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>DOHOL.IS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KAYSE.IS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KONTR.IS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Kod  f_score\n",
       "0    LOGO.IS        9\n",
       "1   GSRAY.IS        8\n",
       "2   KARSN.IS        7\n",
       "3   SARKY.IS        7\n",
       "4   ECILC.IS        7\n",
       "5   BFREN.IS        7\n",
       "6   TKFEN.IS        7\n",
       "7    ADEL.IS        6\n",
       "8   GUBRF.IS        6\n",
       "9    DOAS.IS        6\n",
       "10  CCOLA.IS        6\n",
       "11  ENKAI.IS        6\n",
       "12  TEZOL.IS        6\n",
       "13  OZKGY.IS        6\n",
       "14  TCELL.IS        6\n",
       "15  ATATP.IS        6\n",
       "16  NUHCM.IS        6\n",
       "17  ASELS.IS        6\n",
       "18  AEFES.IS        6\n",
       "19  AGHOL.IS        6\n",
       "20  KUYAS.IS        6\n",
       "21  ISDMR.IS        6\n",
       "22   MAVI.IS        6\n",
       "23  CLEBI.IS        6\n",
       "24  GRSEL.IS        6\n",
       "25  GLYHO.IS        5\n",
       "26  PENTA.IS        5\n",
       "27  DOHOL.IS        5\n",
       "28  KAYSE.IS        5\n",
       "29  KONTR.IS        5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting stocks with highest Piotroski f score to lowest\n",
    "f_score_df = piotroski_f(transformed_df)\n",
    "f_score_df=pd.DataFrame(f_score_df.sum().sort_values(ascending=False))\n",
    "f_score_df.reset_index(inplace=True)\n",
    "f_score_df.rename(columns={\"index\":\"Kod\",0:\"f_score\"},inplace=True)\n",
    "f_score_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7553ffa-a769-4b1a-86c6-7f40d21d7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score_df.to_excel(\"piotroski_f_scores.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc1551e8-78d5-4c7d-b832-13459f505e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kod</th>\n",
       "      <th>f_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>GESAN.IS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>TMSN.IS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>REEDR.IS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>PARSN.IS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>NATEN.IS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>PATEK.IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>BINBN.IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>IEYHO.IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>SRVGY.IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>TUKAS.IS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Kod  f_score\n",
       "158  GESAN.IS        2\n",
       "159   TMSN.IS        2\n",
       "160  REEDR.IS        2\n",
       "161  PARSN.IS        2\n",
       "162  NATEN.IS        2\n",
       "163  PATEK.IS        1\n",
       "164  BINBN.IS        1\n",
       "165  IEYHO.IS        1\n",
       "166  SRVGY.IS        1\n",
       "167  TUKAS.IS        1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_score_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26458ab0-3737-42e5-8db2-526dbd2e6be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef piotroski_f(df_dict):\\n    f_score = {}\\n    for ticker, df in df_dict.items():\\n        if df.empty:  # Eğer DataFrame boşsa atla\\n            print(f\"Skipping {ticker} due to empty dataframe\")\\n            continue\\n        columns = df_dict[ticker].columns\\n        ROA_FS = int(df_dict[ticker].loc[\"NetIncome\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2) > 0)\\n        CFO_FS = int(df_dict[ticker].loc[\"CashFlowOps\",columns[0]] > 0)\\n        ROA_D_FS = int((df_dict[ticker].loc[\"NetIncome\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2)) > (df_dict[ticker].loc[\"NetIncome\",columns[1]]/((df_dict[ticker].loc[\"TotAssets\",columns[1]] + df_dict[ticker].loc[\"TotAssets\",columns[2]])/2)))\\n        CFO_ROA_FS = int(df_dict[ticker].loc[\"CashFlowOps\",columns[0]]/df_dict[ticker].loc[\"TotAssets\",columns[0]] > df_dict[ticker].loc[\"NetIncome\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2))\\n        LTD_FS = int((df_dict[ticker].loc[\"LTDebt\",columns[0]] + df_dict[ticker].loc[\"OtherLTDebt\",columns[0]]) < (df_dict[ticker].loc[\"LTDebt\",columns[1]] + df_dict[ticker].loc[\"OtherLTDebt\",columns[1]]))\\n        CR_FS = int((df_dict[ticker].loc[\"CurrAssets\",columns[0]] / df_dict[ticker].loc[\"CurrLiab\",columns[0]]) > (df_dict[ticker].loc[\"CurrAssets\",columns[1]] / df_dict[ticker].loc[\"CurrLiab\",columns[1]]))\\n        DILUTION_FS = int(df_dict[ticker].loc[\"CommStock\",columns[0]] <= df_dict[ticker].loc[\"CommStock\",columns[1]])\\n        GM_FS = int((df_dict[ticker].loc[\"GrossProfit\",columns[0]]/df_dict[ticker].loc[\"TotRevenue\",columns[0]]) > (df_dict[ticker].loc[\"GrossProfit\",columns[1]]/df_dict[ticker].loc[\"TotRevenue\",columns[1]]))\\n        ATO_FS = int((df_dict[ticker].loc[\"TotRevenue\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2)) > (df_dict[ticker].loc[\"TotRevenue\",columns[1]]/((df_dict[ticker].loc[\"TotAssets\",columns[1]] + df_dict[ticker].loc[\"TotAssets\",columns[2]])/2)))\\n        f_score[ticker] = [ROA_FS,CFO_FS,ROA_D_FS,CFO_ROA_FS,LTD_FS,CR_FS,DILUTION_FS,GM_FS,ATO_FS]\\n    f_score_df = pd.DataFrame(f_score,index=[\"PosROA\",\"PosCFO\",\"ROAChange\",\"Accruals\",\"Leverage\",\"Liquidity\",\"Dilution\",\"GM\",\"ATO\"])\\n    return f_score_df\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def piotroski_f(df_dict):\n",
    "    f_score = {}\n",
    "    for ticker, df in df_dict.items():\n",
    "        if df.empty:  # Eğer DataFrame boşsa atla\n",
    "            print(f\"Skipping {ticker} due to empty dataframe\")\n",
    "            continue\n",
    "        columns = df_dict[ticker].columns\n",
    "        ROA_FS = int(df_dict[ticker].loc[\"NetIncome\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2) > 0)\n",
    "        CFO_FS = int(df_dict[ticker].loc[\"CashFlowOps\",columns[0]] > 0)\n",
    "        ROA_D_FS = int((df_dict[ticker].loc[\"NetIncome\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2)) > (df_dict[ticker].loc[\"NetIncome\",columns[1]]/((df_dict[ticker].loc[\"TotAssets\",columns[1]] + df_dict[ticker].loc[\"TotAssets\",columns[2]])/2)))\n",
    "        CFO_ROA_FS = int(df_dict[ticker].loc[\"CashFlowOps\",columns[0]]/df_dict[ticker].loc[\"TotAssets\",columns[0]] > df_dict[ticker].loc[\"NetIncome\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2))\n",
    "        LTD_FS = int((df_dict[ticker].loc[\"LTDebt\",columns[0]] + df_dict[ticker].loc[\"OtherLTDebt\",columns[0]]) < (df_dict[ticker].loc[\"LTDebt\",columns[1]] + df_dict[ticker].loc[\"OtherLTDebt\",columns[1]]))\n",
    "        CR_FS = int((df_dict[ticker].loc[\"CurrAssets\",columns[0]] / df_dict[ticker].loc[\"CurrLiab\",columns[0]]) > (df_dict[ticker].loc[\"CurrAssets\",columns[1]] / df_dict[ticker].loc[\"CurrLiab\",columns[1]]))\n",
    "        DILUTION_FS = int(df_dict[ticker].loc[\"CommStock\",columns[0]] <= df_dict[ticker].loc[\"CommStock\",columns[1]])\n",
    "        GM_FS = int((df_dict[ticker].loc[\"GrossProfit\",columns[0]]/df_dict[ticker].loc[\"TotRevenue\",columns[0]]) > (df_dict[ticker].loc[\"GrossProfit\",columns[1]]/df_dict[ticker].loc[\"TotRevenue\",columns[1]]))\n",
    "        ATO_FS = int((df_dict[ticker].loc[\"TotRevenue\",columns[0]]/((df_dict[ticker].loc[\"TotAssets\",columns[0]] + df_dict[ticker].loc[\"TotAssets\",columns[1]])/2)) > (df_dict[ticker].loc[\"TotRevenue\",columns[1]]/((df_dict[ticker].loc[\"TotAssets\",columns[1]] + df_dict[ticker].loc[\"TotAssets\",columns[2]])/2)))\n",
    "        f_score[ticker] = [ROA_FS,CFO_FS,ROA_D_FS,CFO_ROA_FS,LTD_FS,CR_FS,DILUTION_FS,GM_FS,ATO_FS]\n",
    "    f_score_df = pd.DataFrame(f_score,index=[\"PosROA\",\"PosCFO\",\"ROAChange\",\"Accruals\",\"Leverage\",\"Liquidity\",\"Dilution\",\"GM\",\"ATO\"])\n",
    "    return f_score_df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293b5c2-de66-4955-a4ec-1c19e13ef015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
